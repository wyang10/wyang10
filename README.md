## Hi there ğŸ‘‹ I am Audrey~ ğŸš€

<!--
**wyang10/wyang10** is a âœ¨ _special_ âœ¨ repository because its `README.md` (this file) appears on your GitHub profile.

Here are some ideas to get you started:

- ğŸ”­ Iâ€™m currently working on ...
- ğŸŒ± Iâ€™m currently learning ...
- ğŸ‘¯ Iâ€™m looking to collaborate on ...
- ğŸ¤” Iâ€™m looking for help with ...
- ğŸ’¬ Ask me about ...
- ğŸ“« How to reach me: ...
- ğŸ˜„ Pronouns: ...
- âš¡ Fun fact: ...
-->

# About Me ğŸŒ± 

ğŸ¯ I'm a Cloud Data Engineer specializing in building scalable, cost-efficient Lakehouse architectures and production-grade ELT pipelines. I design reliable batch & streaming systems that turn messy data into trusted analytics and ML-ready datasets.

---

## Quick pitch ğŸ’¬
-  ğŸ“ Graduated: MSCS at Northeastern University (Jan 2022 â€“ Dec 2024)
-  ğŸ”¹ Focus: Cloud-Native Data Engineering - streaming systems (Kafka/Flink), orchestration (Airflow/Dagster)
-  ğŸ”— Contact: wyang10 (GitHub)  â€¢ www.github.com/wyang10   â€¢ www.linkedin.com/in/awhy

---

## Highlights ğŸ’¡
- End-to-End Cloud Data Systemsï¼ˆAirflow, dbt, Snowflake, BigQuery, Terraformï¼‰
- Advanced Streaming Architectureï¼ˆKafka/Flink, stateful streaming, exactly-once semanticsï¼‰
- Distributed Systems for Data Engineeringï¼ˆidempotency, back-pressure, partitioningï¼‰
- Large-Scale ETL/ELT Optimizationï¼ˆincremental models, orchestration patternsï¼‰
- Feature Engineering Systemsï¼ˆfeature pipelines, online/offline store designï¼‰

---

## Experience ğŸ§©
- Data Engineer â€” LumiereX (Jan 2025 â€“ Present)  
  Led core data platform initiatives, implemented ELT frameworks, and optimized Spark workloads for cost and speed.

- Software Engineer Intern â€” VisionX (Jan 2024 â€“ Jul 2024)  
  Implemented scalable data ingestion pipelines and contributed to ML feature platforms.

---

## Featured Projects ğŸ‘¨â€ğŸ’»

- [airflow_dbt_damo](https://github.com/wyang10/airflow_dbt_demo.git) 
  â€” A production-ready ELT & Data Quality Framework, combining Airflow + dbt + Great Expectations.
  â€” Orchestration for reproducible, turning manual workflows into an automated, auditable orchestration system. 

- [Macro-Market-Intelligence-Pipeline](https://github.com/wyang10/Macro-Market-Intelligence-Pipeline.git)
  â€” Automates the process of collecting, analyzing, and summarizing macroeconomic signals from multiple data sources
  â€” including EDGAR filings, and public macro indicators (VIX, DXY, UST10Y). It produces a weekly Markdown + HTML report.
  
---

## How I work / What I enjoy ğŸ‘¯
- Designing modular, testable pipelines that are easy to operate and debug.
- Choosing trade-offs that optimize for team velocity, observability, and cloud spend.
- Mentoring teammates on data modeling, pipeline testing, and operational best practices.

---

## Core Skills âš¡ 

**Languages & Tools**
- Python (Pandas, PySpark), SQL, Java, Scala, Bash

**Cloud & Orchestration**
- GCP: BigQuery, Dataflow
- AWS: S3, EMR, Glue, Lambda, Step Functions, IAM
- Orchestration: Airflow, dbt, Docker, GitHub Actions, Kubernetes

**Big Data & Storage**
- Spark, Flink, Kafka, Hive, HDFS, Databricks
- Delta Lake, Snowflake, Parquet, star-schema modeling

**Data Quality & CI**
- Great Expectations, dbt tests, automated lineage & monitoring

---

## ğŸ˜„ Thanks for stopping by! ğŸ‘‹
